
\chapter{Dynamic Pricing \& Ordering Optimization Models}
This chapter presents dynamic optimization models for dynamic pricing and ordering problems.
The goal is to find merchant strategies that maximize expected long-term profits.
The setting is an online marketplace in which our merchant competes with other merchants in an oligopoly.

We estimate demand based on historical market data using demand learning with linear regression.
The estimated demand is used in dynamic programming to generate optimized pricing and ordering policies.

A pricing policy defines a pricing decision for every situation a merchant can be in. Similar, an ordering policy defines an ordering decision for every such situation.
In our case, pricing and ordering decisions depend on the current inventory level and on the current market situation.

We developed the optimization model in four phases to overcome the complexity of joint pricing and ordering problem under competition.
The first phase in \cref{section:ordering} is constrained to the ordering problem with known customer demand in a monopoly.
Each following phase adds a new difficulty the merchant must manage.
\cref{section:joint_ordering_pricing} describes the second phase, which adds free choice over the offer price.
The merchant's chosen price will affect sales.
In the third phase (\cref{section:demand_learning}), demand is no longer known and the merchant has to find ways to estimate future demand.
The fourth and last phase (\cref{section:competition}) represents the final problem: The joint ordering and dynamic pricing problem with uncertain customer behavior under competition.
\cref{section:merchant_implementation} describes our merchant implementation for the \pricewars platform.

\section{Ordering Problem in Monopoly}
\label{section:ordering}
The merchant focuses on the ordering problem in this scenario and makes ordering decisions that promise the most expected long-term profit.
The merchant cannot make pricing decisions, instead all products are sold at a fixed price.
Ordering decisions depend on the customer demand.
The demand is stochastic and its distribution is known to the merchant.
There are no backlogs.
If a customer arrives while the merchant is out of stock, the merchant will miss the sale.
The merchant operates in a monopoly and does not have to care about competitors.

\subsection{Model of Ordering Problem}
\label{subs:ordering_model}
%situation
The merchant sell items over the marketplace.
% price & revenue
Items are offered at a fixed price $a_{fix}$, $a_{fix} > 0$ and each sold item generates the full offer price $a_{fix}$ as revenue.
%discounting
We use discounting to increase the relevance of short-term profits.
A discount factor $\delta$, $0 < \delta \leq 1$, is applied to each time period.
% time horizon
% write about t here?
The time horizon is infinite.
% discrete time %why use discrete time?
The merchant makes exactly one order decision in each discrete time period.

% inventory + holding cost
The merchant holds items in an inventory.
Storing items in the inventory causes holding costs of $l$ per item per time period, $l > 0$.
The random inventory level at the start of period $t$ is denoted by $N_t$, $t = 0, 1, \ldots$

%ordering
The merchant can reorder items to increase the inventory level.
The number of items ordered at time $t$ are denoted by $b_t$, $b_t \geq 0$.
An order of size $b_t = 0$ means that no order is made.
%todo order delay
The set of admissible orders quantities is denoted by $B$, $B \subseteq  \mathbb{N}$.
% order cost
Each order causes order costs, which consists of fixed order costs $c_{fix}$, $c_{fix} \geq 0$, and variable order costs $c_{var}$, $c_{var} \geq 0$.
Order decisions influence the merchant's profit based on ordering costs, holding costs, and future potential sales.
%order costs paid upfront
Order costs are defined by, $b \in B$,

\begin{equation}
\label{eq:order_cost}
C(b) := \begin{cases}
	c_{fix} + c_{var} \cdot b  & \quad \text{if } b > 0 \\
	0  & \quad \text{if } b = 0
\end{cases}
\end{equation}

%sales
The probability to sell $i$ items within one period of time, given enough items are available, is denoted by $P(i)$, $i = 0, 1, \ldots$ .
A changing customer behavior over time is out of scope of this work, thus the sales probability $P(i)$ does not depend on the time period $t$.
The sales probability in the first phase does not directly depend on the price or market situation because the merchant sells at a fixed price in a monopoly.
The random number of sold items within the period $(t-1, t)$ is denoted by $X_t$.
The merchant cannot sell more items than the inventory holds, i.e. $N_t \geq X_{t+1}$, $t = 0, 1, \ldots$

%whats ordering strategy?
%how to write the policy?
Depending on a given ordering policy $(b_t)_t$, the random accumulated discounted profit from time period $t$ is, $t = 0, 1, \ldots$

$$
G_t := \sum_{s=t+1}^{\infty} \delta^{s-t} \cdot (a_{fix} \cdot X_s - l \cdot N_{s-1} - C(b_{s-1}(N_{s-1})))
$$

The objective is to find an ordering policy that maximizes the expected total profit $E(G_0 | N_0)$.
A list of all variables and parameters with description is given in \cref{tab:notations}.

% end of model descripiton, maybe write what comes next
%Sales decrease the inventory level over time and orders increase it.

\subsection{Dynamic Programming Approach}
\label{section:ordering_solution}
%why use dyn prog? -> optimal; why optimal?

%what? -> dyn programming
Goal of this section is to derive optimal ordering policies for the ordering problem.
We use a dynamic programming approach to find the ordering policy promises the best expected profit for the stochastic control problem.
The value function $V_t(n)$, $t, n = 0, 1, \ldots$, describes the best expected discounted future profit $E_t(G_t | N_t=n)$.
$N_{max}$ denotes an upper limit of the inventory level $n$ and the order decision $b$, $0 \leq n, b \leq N_{max}$. This does not affect the optimal solution as long as $N_{max}$ is greater than the biggest inventory level that can occur in the optimal policy.

%why do we limit time horizon?
We limit the time horizon to the end time $T$.
If $T$ is sufficiently large, the value iteration over $V_t$ converged, so that the optimal ordering policy is not affected.
The start value $u$ defines the result of the value function at the end of the time horizon, $V_T(n) = u$ for all $n$.
For now, the start value is set to $u := 0$.

%instant vs delayed order, zugangübergänge
We consider $V_t(n)$ with \textit{instantaneous} and \textit{delayed} orders.
With instantaneous orders, available items from the start of the time period and the newly ordered items can be sold within that period.
The following time period starts with an inventory of items that were not sold in the previous period.
With delayed orders, only items that are available from the start of the time period can be sold within that period.
The following time period starts with an inventory of items that were not sold in the previous period plus the number of items ordered in the previous period.

The value function with an \textit{instantaneous arrival} of orders is, $t=0,1,\ldots,T$, $n=0,1,\ldots,N_{max}$,
%todo special case P(n_max) -> rest probability
\begin{equation}
\begin{split}
V_t(n) = \max_{b \in B} \Bigg\{
\sum_{i = 0}^{N_{max}}
P(i) \cdot \Big(
a_{fix} \cdot min(i, n + b) %sales
- l \cdot (n + b) % holding cost
- C(b) % order cost
 \\
+ \delta \cdot V_{t+1}\big(min(max(n + b - i, 0), N_{max})\big)
\Big)\Bigg\}
\end{split}
\label{eq:dyn_prog_no_delay}
\end{equation}

%todo: order delay mentioned in model description?
The value function with \textit{order delivery delay} is shown in the following equation, $t=0,1,\ldots,T$, $n=0,1,\ldots,N_{max}$,

\begin{equation}
\begin{split}
V_t(n) = \max_{b \in B} \Bigg\{
	\sum_{i = 0}^{N_{max}} 
		P(i) \cdot \Big(
			a_{fix} \cdot min(i, n) %sales
			- l \cdot n % holding cost
			- C(b) % order cost
		 \\
		+ \delta \cdot V_{t+1}\big(min(max(n - i, 0) + b, N_{max})\big)
	\Big)\Bigg\}
\end{split}
\label{eq:dyn_prog}
\end{equation}

The set of order quantities $B$ is a discrete set of integers and must contain zero to allow the merchant to make no order.
The optimal ordering decision $b^*(n)$ is given by using arg max on \cref{eq:dyn_prog_no_delay,eq:dyn_prog}.

That is for instantaneous orders, $n=0,1,\ldots,N_{max}$,

\begin{equation}
\begin{split}
b^*_{instant}(n) = \argmax_{b \in B} \Bigg\{
\sum_{i = 0}^{N_{max}}
P(i) \cdot \Big(
a_{fix} \cdot min(i, n + b) %sales
- l \cdot (n + b) % holding cost
- C(b) % order cost
\\
+ \delta \cdot V_{1}\big(min(max(n + b - i, 0), N_{max})\big)
\Big)\Bigg\}
\end{split}
\label{eq:optimal_order_instant}
\end{equation}

and for delayed orders, $n=0,1,\ldots,N_{max}$,

\begin{equation}
\begin{split}
b^*(n) = \argmax_{b \in B} \Bigg\{
\sum_{i = 0}^{N_{max}} 
P(i) \cdot \Big(
a_{fix} \cdot min(i, n) %sales
- l \cdot n % holding cost
- C(b) % order cost
 \\
+ \delta \cdot V_{1}\big(min(max(n - i, 0) + b, N_{max})\big)
\Big)\Bigg\}
\end{split}
\label{eq:optimal_order}
\end{equation}

Equations \cref{eq:optimal_order_instant,eq:optimal_order} are comparable to $V_0(n)$ but use $\argmax$ instead of $\max$. The $\argmax$ is only used on the outermost term.
Nested functions are normal value functions using $\max$.
Since \cref{eq:optimal_order_instant,eq:optimal_order} correspond to $V_0(n)$, the next nested value function is $V_1(n)$.

Equations \cref{eq:optimal_order_instant,eq:optimal_order} yield optimal policies to the ordering problem without and with order delay, respectively.
The duration of the order delay in \cref{eq:optimal_order} is exactly the length of one period.
It is possible to find optimal ordering policies for arbitrary order delays using this dynamic programming approach.
However, this greatly increases the dynamic programming state and results in long computation times.
In order have reasonable decision times for the merchant, we use the presented approach, which is a heuristic for order delays different from the length of the time period and otherwise an exact solution.
The following phases will only consider the variation with delayed orders.

\subsection{Numeric Example}
\label{section:order_example}
This section shows explicit results of \cref{eq:optimal_order_instant,eq:optimal_order} for parameters given by the following example.

\begin{example}
	\label{example:order}
	Let the parameters be $N_{max} = 40$, $a_{fix} = 35$, $c_{fix} = 30$, $c_{var} = 20$,
	$l = 0.4$, $T = 500$, $\delta = 1$, $B = \{0, 1, \ldots, 40\}$, $t = 0, 1, \ldots, T-1$, $u=0$. The length of a period is one second. Sale probabilities $P(i)$ are taken from \cref{tab:sale_probs}
\end{example}

The time between arriving customers is exponential distributed with a mean time of one second.
We simulated this process to get the following sales probabilities.

\begin{table}
\centering
\begin{tabular}{llllllllll}
	\toprule
	$i$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & other \\
	\midrule
	$P(i)$ & 0.189 & 0.316 & 0.261 & 0.146 & 0.061 & 0.020 & 0.006 & 0.001 & 0.0\\
	\bottomrule
\end{tabular}
\caption[Sale Probabilities for \cref{example:order}]{Probabilities to sell $i$ items in one period, given enough items are available. The probabilities are based on a simulation of customer arrivals with exponential distributed waiting time between customers.}
\label{tab:sale_probs}
\end{table}

\begin{table}[t]
	\centering
	\begin{tabular}{rrr}
		\toprule
		$n$ & $b^*_{instant}(n)$ & $b^*(n)$ \\
		\midrule
		0 & 17 & 18 \\
		1 & 16 & 18 \\
		2 & 0 & 17 \\
		3 & 0 & 16\\
		other & 0 & 0 \\
		\bottomrule
	\end{tabular}
\caption[Numeric Example: Ordering Policies]{Ordering policies without and with order delivery delay for \cref{example:order}.}
\label{tab:order_results}
\end{table}

Using \cref{eq:optimal_order_instant,eq:optimal_order} results in ordering policies shown in \cref{tab:order_results}.
The merchant begins to order new items at a higher inventory level if orders are delayed.
Additionally, the merchant restocks more items.
This behavior reduces the risks of an stock-out until the ordered items arrive.

%ss-policy
The optimal policy for the ordering problem with instantaneous order delivery falls into the class of ($s$, $S$) policies.
Policies of this class are identified by two parameters.
Parameter $s$ is a threshold on the inventory level.
If the inventory level falls below or to $s$, the merchant orders new items.
The merchant orders as many items as needed to increase the inventory level to $S$.
In our example, the resulting policy is a (1, 17) policy.
The merchant orders if the inventory level is one or fewer and refills the inventory to 17 items.
With delayed order delivery, the optimal policy is not a ($s$, $S$) policy because the inventory is refilled to different levels.

\begin{table}
	\centering
	\begin{tabular}{rrrrrr}
		\toprule
		& no change & $l= 0.1$ & $c_{fix} = 15$ & $c_{var} = 27$ & $a_{fix} = 55$ \\
		$n$ & $b^*(n)$ & $b^*(n)$ & $b^*(n)$ & $b^*(n)$ & $b^*(n)$ \\
		\midrule
		0 & 18 & 35 & 14 & 17 & 19\\
		1 & 18 & 34 & 13 & 17 & 19\\
		2 & 17 & 34 & 13 & 16 & 18\\
		3 & 16 & 33 & 12 &  0 & 17\\
		4 &  0 & 32 & 11 &  0 & 17\\
		other & 0 & 0 & 0 & 0 &  0\\
		\bottomrule
	\end{tabular}
	\caption[Effect of Parameter Changes on Optimal Ordering Policy]{Effect of parameter changes on optimal ordering policy $b^*(n)$.
	Each column shows the results of $b^*(n)$ when changing one parameter.
	If not chosen differently, parameters are as in \cref{example:order} with $l=0.4$, $c_{fix}=30$, $c_{var}=20$, $a_{fix}=35$.}
	\label{table:order_policy_parameter}
\end{table}


\cref{table:order_policy_parameter} shows the effect of different parameters on $b^*(n)$.
When holding costs decrease, the merchant makes bigger orders because it is less costly to hold these items in the inventory.
The merchant buys less items per order if fixed order costs are lower.
This results in more frequent orders and an on average lower inventory level, which saves holding costs.
Higher variable order costs reduce the merchant's profit margin.
The merchant orders only in few different sizes that promise the best trade-off between holding costs and order costs.
The merchant risks stock-outs to avoid high order costs. 
If variable order costs are too high, the stops ordering completely.
At a higher selling price, the merchant orders more products and refills the inventory earlier.
The loss of potential revenue becomes more important than the additional holding costs.

\subsection{Effect of Start Value on Convergence of Value Function}
\label{section:convergence}
In \cref{section:ordering_solution}, we used an arbitrary start value $u := 0$ and claimed that the value function $V_0(n)$, $n=0,1,\ldots,N_{max}$, converges to the optimal expected profit if $T$ is sufficiently large.
In the following example, we show that the value function converges to the same value independently from $u$.

\begin{figure}[t]
	\begin{tikzpicture}
	\begin{axis}[
	title={Convergence of $V_0(0)$ for different start values $u$},
	xlabel={$T$},
	ylabel={$V_0(0)$},
	legend pos=north east,
	grid style=dashed,
	axis lines = left,
	width=0.8\textwidth,
	]
	
	\addplot+[mark=none]
	coordinates {(5, 420.70235436191115)
		(10, 378.70641501244478)
		(15, 346.02067386424631)
		(20, 320.58230246540893)
		(25, 300.88897170076484)
		(30, 285.65349940578312)
		(35, 273.8651312577353)
		(40, 264.74349735259943)
		(45, 257.68533426566137)
		(50, 252.22386101489249)
		(55, 247.99787744298365)
		(60, 244.72789197784797)
		(65, 242.19763955718636)
		(70, 240.23977846509317)
		(75, 238.72482287360947)
		(80, 237.55257911579616)
		(85, 236.64551924190459)
		(90, 235.94365360231592)
		(95, 235.40056334971575)
		(100, 234.98033046491173)};
	\addlegendentry{$u = 500$}
	
	\addplot+[mark=none]
	coordinates {(5, 188.56807311191125)
		(10, 199.08533324093116)
		(15, 207.03330481632042)
		(20, 213.03652574284629)
		(25, 217.67209976421481)
		(30, 221.26187022290196)
		(35, 224.04011606145312)
		(40, 226.18985038306852)
		(45, 227.85325716953369)
		(50, 229.14036843187844)
		(55, 230.13631091132481)
		(60, 230.90695228176233)
		(65, 231.50325988201828)
		(70, 231.9646713340606)
		(75, 232.32170271984614)
		(80, 232.59796680029206)
		(85, 232.81173467946479)
		(90, 232.9771441894182)
		(95, 233.10513491510116)
		(100, 233.20417169881145)};
	\addlegendentry{$u = 200$}
	
	\addplot +[mark=none]
	coordinates {
		(5, 33.811885611911237)
		(10, 79.337945393255367)
		(15, 114.37505878436978)
		(20, 141.33934126113792)
		(25, 162.19418513984795)
		(30, 178.33411743431449)
		(35, 190.82343926393168)
		(40, 200.48741907004785)
		(45, 207.96520577211518)
		(50, 213.75137337653584)
		(55, 218.2285998902189)
		(60, 221.69299248437193)
		(65, 224.37367343190618)
		(70, 226.44793324670562)
		(75, 228.05295595067062)
		(80, 229.29489192328936)
		(85, 230.25587830450493)
		(90, 230.99947124748647)
		(95, 231.57484929202485)
		(100, 232.02006585474473)};
	\addlegendentry{$u = 0$}
	%policy converged:
	%\addplot[mark=*] coordinates {(8,394.912775771)};
	%\addplot[mark=*] coordinates {(8,195.886646384)};
	%\addplot[mark=*] coordinates {(8,63.202560126)};
	\end{axis}
	\end{tikzpicture}
	\caption[Effect of Start Value on Convergence of Value Function]{Influence of start value $u$ on the final expected discounted profit $V_0$. The function converges with any start value to the same expected profit, given a sufficiently large $T$. However, $V_0$ converges faster if $u$ is near the resulting expected discounted profit. Parameters as in \cref{example:order}, $\delta=0.95$. $T=100$.}
	\label{fig:convergence}
\end{figure}

\cref{fig:convergence} shows results of $V_0(0)$ with varying $T$ and start values $u$.
The parameters are as in \cref{example:order}.
The only differences are $\delta = 0.95$ and $T = 100$.
The value function converges to the same result for any $u$.
It does not matter if the start value is bigger or smaller than the resulting expected profit.
However, the value function converges faster if $u$ is near the optimal expected discounted profit.
%direct ref to section?
We will use this fact in later sections to speed up the policy computation.

% show V_0 for different n, no big difference in result
%todo{compare different n}

\section{Joint Ordering and Pricing Problem}
\label{section:joint_ordering_pricing}
%What?
In this section, the merchant is in the same situation as in \cref{section:ordering} but additionally gains control over the selling price.
With ordering and pricing decisions enabled, the merchant's actions on the marketplace are unconstrained.
%Difference in demand
Demand in this scenario depends on the chosen selling price.
A higher price typically results in less demand.
As in the previous problem, the demand distribution is known.

%Why joint:
We cannot separate the inventory and pricing problem and solve each in isolation to solve the whole problem optimally.
Ordering and pricing decisions influence each other.
Setting a price changes the demand, which requires a different ordering policy.
The other way around, an ordering policy might require certain prices for a better control over inventory levels.
This mutual influence is the reason, why ordering and pricing should be decided jointly.
However, this is a more complex problem compared to solving the ordering problem and pricing problem separately.

\subsection{Model of Ordering and Pricing Problem}
\label{subs:joint_model}
This model is an extension of the model from \cref{subs:ordering_model}.
%pricing decision
Instead of a fixed selling price $a_{fix}$, the merchant sets a price $a_t$ in each period $t$, with $a_t \geq 0$, $t=0,1,\ldots,T$.
The set of admissible pricing decisions is denoted by $A$, $A \subseteq  \mathbb{N}$.
%revenue
Each sold item in period $t$ generates a revenue of $a_t$.

%demand
The probability to sell $i$ items, $i=0,1,\ldots$, given enough items are available, depends now on price $a$.
The merchant knows the price-dependent probability distribution in this scenario.

Depending on a given pricing and ordering policy $(a_t, b_t)_t$, which can depend on the current inventory level, the random accumulated discounted profit from time period $t$ is, $t=0,1,\ldots$

$$
G_t := \sum_{s=t+1}^{\infty} \delta^{s-t} \cdot (a_{s-1}(N_{s-1}) \cdot X_s - l \cdot N_{s-1} - C(b_{s-1}(N_{s-1})))
$$

The objective is to find a joint pricing and ordering policy that maximizes the expected discounted total profit $E(G_0 | N_0)$.

\subsection{Extending the Dynamic Programming Approach by Pricing Decisions}
\label{section:joint_solution}
As a basis, we use the dynamic programming approach shown in \cref{eq:dyn_prog}.
The action space is extended by one dimension that contains all potential pricing decisions $A$.
This resulting equation is, $t=0, 1, \ldots,T$, $n = 0,1,\ldots,N_{max}$

\begin{equation}
\begin{split}
V_t(n) = \max_{\substack{a \in A \\ b \in B}} \Bigg\{
\sum_{i = 0}^{N_{max}}
P(i, a) \cdot \Big(
a \cdot min(i, n) %sales
- l \cdot n % holding cost
- C(b) % order cost
 \\
+ \delta \cdot V_{t+1}\big(min(max(n - i, 0) + b, N_{max})\big)
\Big)\Bigg\}
\end{split}
\label{eq:dyn_prog_joint}
\end{equation}

There are three changes to the value function.
The probability $P(i, a)$ is price-dependent, the revenue in one period depends on the chosen price ($a \cdot min(i, n)$), and the action space is extended by the set of pricing decisions $A$.
The optimal ordering policy $b^*_t(n)$ and pricing policy $a^*_t(n)$ are given by, $n=0,1,\ldots,N_{max}$

\begin{equation}
\begin{split}
(a^*(n), b^*(n)) = \argmax_{\substack{a \in A \\ b \in B}} \Bigg\{
\sum_{i = 0}^{N_{max}}
P(i, a) \cdot \Big(
a \cdot min(i, n) %sales
- l \cdot n % holding cost
- C(b) % order cost
 \\
+ \delta \cdot V_{1}\big(min(max(n - i, 0) + b, N_{max})\big)
\Big)\Bigg\}
\end{split}
\label{eq:joint_best_price_order}
\end{equation}

%todo schreibe hier irgendwas hin, nicht mit gleichungen enden

\subsection{Numeric Example}
\label{section:joint_example}
This section shows the explicit results of \cref{eq:joint_best_price_order} for parameters specified in the following example.

\begin{example}
Let the parameters be $N_{max} = 10$, $c_{fix} = 5$, $c_{var} = 15$, $l = 0.5$,
$T = 500$, $\delta = 1$, $A = \{0, 1, \ldots, 60\}$, $B = \{0, 1, \ldots, 10\}$.
$P(i, a)$ is given by \cref{eq:example_joint_prob}.
Time periods have a length of one second.
\label{example:joint}
\end{example}

For this example, we model sales probabilities with a Poisson distribution.
The mean of potential sales per period $\lambda(a)$ is chosen to be highest if $a = 0$ and zero for $a \geq 40$.
The probability function is, $0 \leq i \leq N_{max}, a \in A$,
%say more about this function? why this function? efect of price on function result?

\begin{equation}
\lambda(a) = \max(2 - 0.05 \cdot a, 0)
\end{equation}
\begin{equation}
P(i, a) = \frac{\lambda(a)^i \cdot e^{-\lambda(a)}}{i!}
\label{eq:example_joint_prob}
\end{equation}

\begin{table}[t]
	\centering
	\begin{tabular}{rrr}
		\toprule
		$n$ & $a^*(n)$ & $b^*(n)$ \\
		\midrule
		0 & - & 5 \\
		1 & 29 & 4 \\
		2 & 29 & 0 \\
		3 & 29 & 0\\
		4 & 28 & 0\\
		5 & 28 & 0\\
		6 & 27 & 0\\
		7 & 27 & 0\\
		8 & 27 & 0\\
		9 & 26 & 0\\
		10 & 26 & 0\\
		\bottomrule
	\end{tabular}
\caption[Numerical Example: Joint Pricing and Ordering Policy]{
Optimal joint pricing and ordering policies for \cref{example:joint}.
The price decreases with increasing inventory level.
$a^*(0)$ has no meaningful result because the merchant cannot offer items to any price if the inventory is empty.
}
\label{tab:example_joint}
\end{table}

Using \cref{eq:joint_best_price_order} results in policies shown in \cref{tab:example_joint}.
The pricing policy sets decreasing prices with increasing inventory levels.
This strategy reduces holding costs for inventories with many items by offering a lower price and selling items faster.
If only few items remain in inventory, the policy uses higher prices to increase the profit per sold product and increase the time until a new order is necessary.

%todo compare different parameters, effect on price or on order

%see jointness of inventory and pricing

\section{Demand Learning}
\label{section:demand_learning}

This section extends the joint inventory and dynamic pricing problem from \cref{section:joint_ordering_pricing} by not providing the merchant with sales probabilities.
%the merchant, the merchant, the merchant...
The merchant needs to estimate the customer behavior in order to make effective ordering and pricing decisions.
The merchant can get information about the customer behavior from past customer actions.
The merchant can analyze historical market situation and sales in order to deduce future sales probabilities.
%what is this dat, where is it from? (how does it look like?)
This is called demand learning.

%from data to demand distribution

%model section removed, maybe mention somewhere that problem is same, only prob is not know

\subsection{Estimating Sales Probabilities}
In order to overcome the inventory and dynamic pricing problem with missing demand information, we split the whole problem into two parts.
The first part is the training of a model from historical market situations and sales in order to predict sales probabilities.
These probabilities are used in the second part to create optimized ordering and pricing policies.
%why sales prob = demand prob? check whole section
Given predicted sales probabilities, the dynamic programming solution from \cref{section:joint_solution} can be used as it is, to calculate ordering and pricing policies.

Assuming, the merchant predicts sales probabilities correctly, the dynamic programming approach creates optimal policies.
In other cases, the quality of policies will depend on the accuracy of predictions. 
The separation of demand prediction and policy creation lets us focus on the prediction of the demand probabilities, while having a working solution for the policy creation.

%bring data into right form
In order to use market and sales data for demand learning, it must be transformed into a usable form.
From the market data we know, at what times the market situation changed and what the market situation was.
The sales data contains information about all of a merchant's sales, including when the sales happened.
These two data sources can be combined and aggregated to a form that contains the number of sales per time period for each market situation.
The size of a period corresponds the period in which the merchant makes a order and pricing decision.

%bring data into right form, part 2 feature extraction
We use regression analysis for the demand learning.
Regression analysis models and analyzes the relationship between a dependent variable and explanatory variables.
In this case, the dependent variable is the sales per period metric.
Explanatory variables are extracted from a market situation $\vec{s}$.
A market situation $\vec{s}$ is a vector of all open offers at one point in time.
In this scenario, the demand depends only on the merchant's price.
%motivation: why use linear regression and not something else? is relationship linear?
We use linear regression to find a relationship between the explanatory variables $\vec{x}(\vec{s})$ of a market situation $\vec{s}$ and the sales per period for this situation.
The following equation shows how to predict mean sales per period for a market situation $\vec{s}$.

\begin{equation}
\label{eq:linear_regression}
\lambda(\vec{s}; \vec{\beta}) = \max(\vec{x}(\vec{s})^\intercal \cdot \vec{\beta}, 0)
\end{equation}

$\vec{\beta}$ is a vector of weights for the regression model.
The number of explanatory variables is denoted by $M$.
Then is $\vec{\beta} := (\beta_0, \ldots, \beta_{M-1})$, $\beta_i \in \mathbb{R}$, $i=0, 1, \ldots, M-1$ and $\vec{x}(\vec{s}) \in \mathbb{R}^M$.
$\lambda(\vec{s}; \vec{\beta})$ has a lower limit of 0 to prevent negative mean sales.
Given observed sales per period $y_1, y_2, \ldots, y_J$ from $J$ historical market situations $\vec{s}_1, \vec{s}_2, \ldots, \vec{s}_J$, the optimal weights $\vec{\beta}^*$ are given by the linear least squares objective, $j=1, 2, \ldots, J$,

\begin{equation}
 \min_{\vec{\beta} \in \mathbb{R}^M}{\sum_{j=1}^J
	{(y_j - \lambda(\vec{s}_j; \vec{\beta}))^2}
}
\label{eq:least_squares_objective}
\end{equation}

The optimal weight can be calculated with the following equation:

\begin{equation}
\vec{\beta}^* = \bigg(\sum_{j=1}^J{\vec{x}(\vec{s}_j) \vec{x}(\vec{s}_j)^\intercal} \bigg)^{-1}
			  \bigg(\sum_{j=1}^J{y_j \vec{x}(\vec{s}_j)} \bigg)
\end{equation}

%predicted mean demand -> distribution
The merchant is able to predict mean sales per period for a market situation with the regression analysis.
However, sales probabilities are needed for the dynamic programming approach.
The mean sales per period can be used as a parameter to create a suitable probability distribution.
%find better citation with a study or something to show that.
We describe the demand distribution with a Poisson distribution.
This discrete distribution is a good approximation for the arrival and buying process of customers \cite{DBLP:journals/ior/Wolff82}.
Equation \cref{eq:probability} shows the calibration of the Poisson distribution with the linear regression from \cref{eq:linear_regression} in order to obtain estimated sales probabilities for a market situation $\vec{s}$, $i = 0,1,...$

\begin{equation}
\label{eq:probability}
P(i, \vec{s}; \vec{\beta}^*) :=
	e^{-\lambda(\vec{s}; \vec{\beta}^*)}
	\frac{\lambda(\vec{s}; \vec{\beta}^*)^{i}}{i!}
\end{equation}

This sales probability function is used in \cref{eq:joint_best_price_order} to calculate optimal ordering and pricing policies.

%retraining
The merchant has access to a steadily growing collection of market situations and sales data over time.
The quality of predictions is increased by periodic training that utilize the new data.
There is no sales data available at the start of a merchant's career on the online marketplace.
In that case, we use a rule-based ordering and pricing strategy until enough training data is available.
The rule-based pricing strategy sets random prices to explore the customer behavior in different market situations.
The exploration pricing strategy sets random prices.
This allows the merchant to encounter many different market situations and obtain sales data for these situations.

%features + algo
Our explanatory variables $\vec{x}$ consist of the price $a$ and the constant intercept 1.
Other variations like $\sqrt{a}$ or $a^2$ are possible to recognize non-linear relations between demand and price.
$\vec{x}$ will be extended by additional variables in the next phase.
Additionally, the linear regression algorithm can be easily replaced by another regression approach like decision tree regression.

\subsection{Comparing Predicted and Actual Sales Probabilities}
\label{section:prediction_quality}

This is an experiment to evaluate how close predicted sales probabilities of our demand learning approach are to the actual underlying sales probabilities.
For the first example, the probability function to sell $i$ items in one period at price $a$ is the following price-dependent Poisson distribution, $a \geq 0$, $i \geq 0$

\begin{equation}
\lambda(a) = \max(2 - 0.05 \cdot a, 0)
\end{equation}
\begin{equation}
P^*(i, a) = \frac{\lambda(a)^i \cdot e^{-\lambda(a)}}{i!}
\end{equation}

We generated ten market situations as training data.
Prices for those situations is chosen uniform randomly between 20 and 40.
The sales per period for a market situation is a random sample from the distribution given by $P^*(i, a)$ and the price of that situation.

\begin{figure}[t]
	\begin{tikzpicture}
	\begin{axis}[
	xlabel={\# Potential Sales $i$},
	ylabel={Probability},
	legend pos=north east,
	grid style=dashed,
	axis lines = left,
	width=0.8\textwidth,
	]
	
	\addplot
	coordinates {
	(0, 0.5487588809622691)
	(1, 0.32930808117346455)
	(2, 0.098808252666443275)
	(3, 0.019764816703365287)
	(4, 0.0029651975071078546)
	(5, 0.00035588071017776061)
	(6, 3.5593772863649323e-05)
	(7, 3.0513836248337362e-06)
	(8, 2.288904383324273e-07)
	(9, 1.5261807378463293e-08)
	(10, 9.1585515558814589e-10)	
	};
	\addlegendentry{$P(i, 30)$}
	
	\addplot
	coordinates {
		(0, 0.60653065971263342)
		(1, 0.30326532985631671)
		(2, 0.075816332464079192)
		(3, 0.012636055410679865)
		(4, 0.0015795069263349827)
		(5, 0.0001579506926334984)
		(6, 1.3162557719458204e-05)
		(7, 9.4018269424701431e-07)
		(8, 5.8761418390438375e-08)
		(9, 3.2645232439132407e-09)
		(10, 1.6322616219566214e-10)	
	};
	\addlegendentry{$P^*(i, 30)$}
	
	\end{axis}
	\end{tikzpicture}
	\caption[Comparison of Predicted Probabilites with Underlying Poisson Probabilities]{Comparison of predicted sales probabilities $P$ with actual underlying Poisson probabilities $P^*$ for a price of 30. The predictions are close to the actual probabilities despite using only ten training examples scattered over a large price range.}
	\label{fig:probs_poisson}
\end{figure}

The generated training examples are used to train the demand learning model.
\cref{fig:probs_poisson} shows sales probability predicted with \cref{eq:probability} compared to actual probabilities.
The predictions are close to the actual probabilities.
This was possible despite only using only ten training examples scattered over a large price range.

This is an ideal example because the underlying probability distribution as well as the distribution used in the demand learning model are both Poisson distributions.
In a second example, we want to evaluate the quality of predictions in a less ideal situation.
We use a binomial distribution as the true underlying probability distribution, $a \geq 0, 0 \leq i \leq 10$

$$
\gamma(a) = \max(-0.025 a + 1, 0)
$$
$$
P^*(i, a) = \binom{10}{i} \gamma(a)^i (1 - \gamma(a))^{10-i}
$$

Ten customers arrive every period and each customer has the price-dependent probability $\gamma(a)$ to buy a product.
We chose parameters for $\gamma(a)$ to have a buy probabilities between 0.5 and 0.0 in the price range of 20 to 40.

\begin{figure}[t]
	\begin{tikzpicture}
	\begin{axis}[
	xlabel={\# Potential Sales $i$},
	ylabel={Probability},
	yticklabel style={/pgf/number format/fixed},
	legend pos=north east,
	grid style=dashed,
	axis lines = left,
	width=0.8\textwidth,
	]
	
	\addplot
	coordinates {
		(0, 0.055035122544745955)
		(1, 0.15958995160415879)
		(2, 0.23138817063876224)
		(3, 0.22365854898079837)
		(4, 0.16214035400158086)
		(5, 0.094034391318580851)
		(6, 0.045446565955699625)
		(7, 0.01882645877781685)
		(8, 0.006824082300322578)
		(9, 0.0021987069624206869)
		(10, 0.00063757746235443334)	
	};
	\addlegendentry{$P(i, 30)$}
	
	\addplot
	coordinates {
		(0, 0.056313514709472684)
		(1, 0.18771171569824247)
		(2, 0.28156757354736334)
		(3, 0.25028228759765653)
		(4, 0.14599800109863295)
		(5, 0.058399200439453194)
		(6, 0.016222000122070344)
		(7, 0.0030899047851562552)
		(8, 0.00038623809814453147)
		(9, 2.8610229492187517e-05)
		(10, 9.5367431640625e-07)	
	};
	\addlegendentry{$P^*(i, 30)$}
	
	\end{axis}
	\end{tikzpicture}
	\caption[Comparison of Predicted Probabilites with Underlying Binomial Probabilities]{Comparison of predicted sales probabilities $P$ with the actual underlying binomial probabilities $P^*$ for a price of 30 based on ten training examples. The predictions are not as close as with the Poisson distribution but still a good approximation.}
	\label{fig:probs_binom}
\end{figure}

Our demand learning model assumes a Poisson distribution and is not able to perfectly fit the underlying binomial distribution.
However, the model is able to approximate that demand distribution, see \cref{fig:probs_binom}.
Observations of customer arrival processes show that the arrivals are close to a Poisson distribution~\cite{DBLP:journals/ior/Wolff82}.
That is the reason why we use a Poisson distribution in our demand learning model.

\begin{figure}[t]
	\begin{tikzpicture}
	\begin{axis}[
	xlabel={\# Training Examples},
	ylabel={L2-norm of $P^* - P$},
	ymin = 0,
	legend style={at={(0.6,0.5)},anchor=west},
	grid style=dashed,
	axis lines = left,
	width=0.8\textwidth,
	]
	
	\addplot +[mark=none]
	coordinates {
		(1, 2.7990831093986261)
		(2, 2.4942065385526502)
		(3, 2.0107306423746754)
		(4, 2.3750736205351455)
		(5, 2.5333371259556645)
		(6, 2.4751883209966872)
		(7, 2.3809476572551471)
		(8, 2.515371985567354)
		(9, 2.9598317786213149)
		(10, 2.9674405445497918)
		(11, 2.9557765940348837)
		(12, 2.9043280219798446)
		(13, 2.9876739675491839)
		(14, 2.9168682697155988)
		(15, 2.9300934940124717)
		(16, 2.9535941937779002)
		(17, 3.0033371925992087)
		(18, 2.9753897331195569)
		(19, 2.9605817834245913)
		(20, 2.8796739402657416)
		(21, 2.8928982722197287)
		(22, 2.8740624457195647)
		(23, 2.8810940805563305)
		(24, 2.8696970651194649)
		(25, 2.8708164539207712)
		(26, 2.8917837415119547)
		(27, 2.8313162430884042)
		(28, 2.8780361724302357)
		(29, 2.9016615802212318)
		(30, 2.8675517466690645)
		(31, 2.8764075783903928)
		(32, 2.8709531932892309)
		(33, 2.8346973157958129)
		(34, 2.8466549217725219)
		(35, 2.7951295013879998)
		(36, 2.7855773244359407)
		(37, 2.7610720987195854)
		(38, 2.7616061421584943)
		(39, 2.7454734207887137)
		(40, 2.7080369159613533)
		(41, 2.697487029492919)
		(42, 2.7224482058206756)
		(43, 2.7226829749176833)
		(44, 2.7221712918231749)
		(45, 2.7001910882309019)
		(46, 2.707569479635354)
		(47, 2.7098257629613105)
		(48, 2.710895063207428)
		(49, 2.6880694088622366)
		(50, 2.6770222001531803)
		(51, 2.6780231588182826)
		(52, 2.6783293732605342)
		(53, 2.7259915966178436)
		(54, 2.7072321383332856)
		(55, 2.7003069632042074)
		(56, 2.6989629882481831)
		(57, 2.6905564104412254)
		(58, 2.6826446153242327)
		(59, 2.680882952358695)
		(60, 2.6702786494438318)	
	};
	\addlegendentry{Binomial Distribution}
	
	\addplot +[mark=none]
	coordinates {
		(1, 2.3408097225373048)
		(2, 2.3408097225373048)
		(3, 2.3408097225373048)
		(4, 2.3408097225373048)
		(5, 0.48134680300906924)
		(6, 1.1147988509758482)
		(7, 1.1058557633983523)
		(8, 1.1923451101893039)
		(9, 1.4800461583051781)
		(10, 1.4779940552616135)
		(11, 1.0213919772692717)
		(12, 1.0517414367475331)
		(13, 0.80826742996421641)
		(14, 0.84997095318394411)
		(15, 0.91765057707335851)
		(16, 0.73371097693612219)
		(17, 0.78998161744680351)
		(18, 0.77514370903203067)
		(19, 0.93782118133382408)
		(20, 0.82285506598223623)
		(21, 0.81513039689305811)
		(22, 0.71115511423147848)
		(23, 0.61753787662182147)
		(24, 0.65395728915256013)
		(25, 0.79338328428385729)
		(26, 0.81232820169052422)
		(27, 0.83639689397835038)
		(28, 0.88226428785627686)
		(29, 0.84189381139602182)
		(30, 0.93607097895494584)
		(31, 0.92125747992770879)
		(32, 0.83981301625457727)
		(33, 0.7459383495332419)
		(34, 0.56377709922604424)
		(35, 0.54905940721141289)
		(36, 0.53936215479001537)
		(37, 0.53227047330654254)
		(38, 0.53860779562581163)
		(39, 0.58142760374804159)
		(40, 0.62292089724018995)
		(41, 0.66980398087719206)
		(42, 0.70917431581954582)
		(43, 0.69973081625407985)
		(44, 0.70748150891920136)
		(45, 0.65830759798632765)
		(46, 0.64569868457548896)
		(47, 0.63942068008239039)
		(48, 0.58161511839266689)
		(49, 0.57976637616598059)
		(50, 0.6323351145581656)
		(51, 0.62001090724659558)
		(52, 0.57728727056498563)
		(53, 0.53161899319675221)
		(54, 0.5254359356670073)
		(55, 0.54158920947738398)
		(56, 0.55244781095628259)
		(57, 0.53829485050204029)
		(58, 0.43034197081541326)
		(59, 0.48447520299968744)
		(60, 0.4719892879873428)	
	};
	\addlegendentry{Poisson Distribution}
	
	\end{axis}
	\end{tikzpicture}
	\caption[Quality of Predictions over the Number of Training Examples]{Quality of sales probability predictions with a true Poisson distribution and a true binomial distribution for different amounts of training examples. The Quality is measured as L2-norm of the difference from predicted to actual probabilities. Lower is better. Our demand learning model predicts Poisson distributed sales probabilities better with increasing numbers of training examples.}
	\label{fig:prediction_quality}
\end{figure}

\cref{fig:prediction_quality} shows the quality of predictions depending on how many training examples are available.
The Quality is measured as L2-norm of the difference from predicted to actual probabilities over the parameters $i = 0, 1, \ldots, 10$ and $a = 20, 21, \ldots, 40$.
Predictions of sales probabilities with an underlying Poisson distribution become more accurate with increasing number of training examples.
Binomial distributed sales probabilities are predicted worse because of our demand learning model's bias towards Poisson distributed sales probabilities.

\section{Pricing \& Ordering Optimization under Competition}
\label{section:competition}
Until now, the merchant offered items on the marketplace in a monopoly.
This is typically not the case on real online marketplaces.
Other merchants offer the same or similar products and everyone competes for market share.
A common strategy to do that is to undercut competitors and offer the cheapest price.
When multiple merchants pursue this strategy, the price will spiral downwards.
Such a commercial competition is called price war.
It is not the best strategy to always undercut the competitors because of decreasing profit margins.
Sometimes it is better to also raise prices.
This reduces sales, but the profit margin is higher.
This section proposes a merchant that makes optimized ordering and pricing decisions under competition with the goal to maximize profit.

In the previous sections, the sales probability was only influenced by the merchant's own pricing decisions.
In this scenario, the merchant's sales probability is also influenced by competitor's offers.
%model description
The model is the same as in \cref{subs:joint_model} with the exception that the number of sold items $X_t$ within a period depends on the merchant's offer price and the competitor's offer prices.
Merchants have access to historical market and sales data.
The market data contains competitors' prices.
However, sales data is limited to the merchant's own sales and does not contain sales from competitors.

%merchant must be fast
Market situations can change frequently on online marketplaces.
A merchant must be able to quickly and effectively react on new market situations in order to offer an suitable price for the new situation.
Getting fast decisions is a challenge because the increasing complexity of the inventory and dynamic pricing problem over the last sections resulting in solutions with increasing computational effort.
Nevertheless, there are ways to improve the speed of the dynamic programming approach which are described in \cref{section:faster_dyn_prog}.

\subsection{Reacting to Competitors' Offers}

%build on top of solution from previous section

%describe two possible approaches
%todo reread, and split paragraph
The inventory level was the only state on which ordering and pricing decisions were based on in the previous problems.
With competitors on the marketplace, the merchant must also consider their offers when making ordering and pricing decisions.
One possible approach is to add competitors' offers to the state in the dynamic programming calculation.
We decided against this solution because it drastically increases the state by multiple dimensions and therefore slows the computation down by multiple orders of magnitude due to the curse if dimensionality.
Moreover, demand learning must predict transitions of competitors' offers from one time period to another.
This means that competitors' strategies must be learned, which requires a substantial amount of training data and a complex demand model to make sensible predictions.

Instead, we take the following approach.
We create ordering and pricing policies whenever the market situation changes for that specific new market situation.
The ordering and pricing decisions for this approach depend only on the merchant's inventory level.
This keeps the computation fast and efficient.
Additionally, only sales probabilities are predicted but not the competitors' price reactions.
This can be done by a relatively simple demand model, which can make good predictions even with few market and sales data.
The disadvantage is that new policies must be computed for each new market situation.

\subsection{Predicting Sales Probabilities under Competition}

%market situation more complex -> more features
Market situations become more complex with the introduction of competition.
Previously, there was at most one active offer at a time.
In this scenario, a market situation can contain as many offers as there are participating merchants.
And the number of offers can change over time when merchants are out of stock.
In \cref{section:demand_learning}, the merchant's offer price was sufficient to describe a market situation.
With competition, the sales probability of an offer depends not only on its price but also on the price of the other offers.
New explanatory variables are necessary for demand learning to describe the more complex market situations.
We created two new explanatory variables besides the offer price in order to describe market situations with competition.
A pricing decision is denoted by $a$ and competitor prices of market situation $\vec{s}$ are denoted by $\vec{p}(\vec{s})$, $\vec{p}(\vec{s}) = (p_1, \ldots, p_K)$ where $K$ is the number of competitor offers in that market situation, $K \in \mathbb{N}^0$.
Our explanatory variables $\vec{x}(a, \vec{s}) = (x_0, x_1, x_2, x_3)$, with intercept $x_0=1$, are:

\begin{description}
	\item [Own price] \hfill \\
		$x_1(a, \vec{s}) := a$ \\
		This explanatory variable holds the value of the merchant's current offer price.
		It helps to explain effects on the sales probability that are based on the total price.
		For example, a higher price generally results in less demand.
	\item [Price rank] \hfill \\
		$x_2(a, \vec{s}) := card(\{k=1,\ldots, K \mid \vec{p}(\vec{s})_k \leq a\})$ \\
		This variable describes the merchant's relative position in the price ranking.
		Even if a price change is small, it can have a huge impact on the sales probabilities if an offer is the cheapest or second cheapest offer.
	\item [Price difference to cheapest offer] \hfill \\
		$x_3(a, \vec{s}) := a - \min( \bigcup_{k=1}^K\{\vec{p}(\vec{s})_k\} \cup \{a\})$ \\
		This is the difference in price from the merchant's offer to the overall cheapest offer.
		If the merchant has the cheapest offer, the variable value will be €0.
		It is a relative variation of the 'own price' metric.
		This variable could explain effects like: a customer is willing to pay €5 more than the cheapest product but not €10 more.
		
		An alternative explanatory variable is the price difference to the cheapest competitor offer. This metric uses the minimum of all prices without the merchants own price $a$.
		This metric contains the information about an price advantage over the cheapest competitor offer.
		However, the edge case must be considered if there are no competitor offers.
\end{description}

With these explanatory variables it is possible to describe the effect of the competition and the merchant's offer price on the sales probabilities.

The predicted sales probability are used in the dynamic programming approach to compute ordering and pricing policy.
As explained above, the policies are computed for each new market situation.
At this point, the computation takes around 10 seconds to complete.
This is too long for the merchant to quickly and frequently react on the changing market.
In the next section, we will reduce this time to allow shorter decision intervals for the merchant.

%todo dyn progamming formula with p(i,x) in demand section

\subsection{Efficient Dynamic Programming}
\label{section:faster_dyn_prog}
Goal of this section is to reduce the time it takes to compute policies using dynamic programming.
This allows the merchant to react faster on new market situations.
We present three approaches to reduce computation time: using a better start value, adapt decision sets, tweaking the number of iterations, and early stopping.
Some approaches trade off some of the value function's accuracy against time efficiency.

%better start value
\cref{fig:convergence} shows that dynamic programming converges faster if the start value $u$ is near the resulting expected profit.
We assume that the expected profit from two successive market situations is similar because the market situations will not fundamentally change in that short time frame.
Setting $V_T(n) = V_0^{old}(n), n=0, 1, \ldots, N_{max}$, where $V_0^{old}(n)$ is the expected discounted profit with a starting inventory of $n$ items from the previous computation, will reduce the time until dynamic programming converges.
Even if the assumption does not hold true and there is a big change in expected profit, the computation converges most of the time faster than with our previous start value $u = 0$.

%adapt decision sets
%very passiv part
Another way to increase the efficiency of the dynamic programming approach is to change the set of pricing decisions $A$ and set of ordering decisions $B$ to only contain relevant decisions.
E.g., a order quantity of 100 is an irrelevant decision if the final policy only uses order quantities around 10.
The irrelevant decision can be removed from the decision set without affecting the result.
The dynamic programming approach is run for a reduced number of periods $T$ for approximations of pricing and ordering policies.
%maybe explain this with min, max
%After that, new decision sets are created, containing the range of decisions that occur in the approximated policy.
%The ranges are increased by some constant to contain decisions that were not used before.
If $A^*_{old}$, $A^*_{old} \subseteq A$, is the set of pricing decisions of the previously computed policy, the adapted pricing decision space is set to

\begin{equation}
A := [\max(\min(A^*_{old}) - d, 0), \max(A^*_{old} + d)]
\end{equation}

If $B^*_{old}$, $B^*_{old} \subseteq B$, is the set of ordering decisions of the previously computed policy, the adapted pricing decision space is set to

\begin{equation}
B := \{0\} \cup [\max(\min(B^*_{old} \setminus \{0\}) - d, 0), \max(B^*_{old} + d)]
\end{equation}

The adaption parameter $d$, $d \in \mathbb{N}^0$, controls how many new decisions are added to the adapted decision sets.
The set of potential ordering decisions is a special case because it must always contain 0.
We narrow pricing decisions to integer prices.
However, this concept can easily be extend to allow steps smaller or greater than 1 between prices.

The new decision sets are used to compute pricing and ordering policies again.
The second dynamic programming computation is faster because it works on a reduced pricing and ordering decision sets.
This process can be repeated in order to adapt the decision sets multiple times.
This approach is not only faster than computing policies on the full decision sets, it also removes the limitation of having a static lower and upper limit on the price and order quantity.
The decision sets can be adapted until they contain relevant decision.
No prior knowledge of relevant prices and order quantities is necessary.
%mention 0 special value for order decisions?
%stop after x iterations or until policy converged
%quantisation (not done here) (range vs stride)

%tweaking iterations
The end time $T$ is a parameter that affects the number of iterations and therefore the computation time of the dynamic programming approach.
The choice of this parameter is a trade-off between precision for large $T$ and efficiency for small $T$.
One observation is that the policy converges faster than the calculated expected profit.
This can be used to reduce $T$ without affecting the precision of the resulting policies.
It is possible to further reduce the end time $T$, if approximations of the optimal pricing and ordering policies are sufficient.

%early stopping
Early stopping ends the computation before reaching $T$ iterations.
This is done if the calculated policies do not change over a number of iterations.
It is likely that these policies already converged to the optimal policies.

\subsection{Evaluation of Efficient Dynamic Programming}

The goal of our efficient dynamic programming approaches is to reduce the computation time in order to be able to react faster to new market situations.
We measured the runtime performance of the dynamic programming variations to show the impact of the optimizations.
All variations calculate pricing and ordering policies for the same market situation for a comparison.
The market situation contains one own offer and two competitor offers.


%baseline
The baseline for the measurements is the pure dynamic programming approach without any of the methods from \cref{section:faster_dyn_prog}.
We set the end time $T = 500$, i.e., iterate 500 times.

%use last value (why faster -> less iterations)
The first optimization method sets the start value $V_T$ to the expected profit from the last computation.
This way $V_T$ is closer to the final expected profit compared to $V_T = 0$.
The value function converges faster with an appropriate start value.
We utilize this fact and reduce the number of iterations to 200 in order to decrease the computation time with only a minimal precision loss.

%adapt decisions (also reuses space)
The next optimization method is the adaption of the ordering and pricing decision sets.
There are 5 successive dynamic programming calculations with 40 iterations each.
This are in total again 200 iterations, but the decision sets are adapted between calculations.
This reduces the size of the decision sets without omitting relevant decisions.
Relevant decisions are decisions that occur in the optimal policy.
Smaller decisions sets lead to a more efficient computation of pricing and ordering policies.
Adapted ordering and pricing decision sets are reused from the previous computation similarly to the start value.

%early stopping
The last optimization method is early stopping.
This stops the dynamic programming calculation if the ordering and pricing policies do not change after a number of iterations.
The assumption is that the polices are already converged, or are almost converged and are close enough to the optimal policy.
Early stopping saves computation time by cutting out iterations that do not have a great impact on the resulting policies.
The results are listed in \cref{tab:speedup}.
Note that each row in the table also contains the optimizations from the rows above.

\begin{table}[t]
	\centering
	\begin{tabular}{ lrr }
		\toprule
		\textbf{Optimization Method} & \textbf{Runtime [ms]} & \textbf{Error [\%]} \\
		\midrule
		Baseline & 9\,425 & 0.53 \\
		\makecell[l]{Set start value to \\ result of previous computation} & 3\,734 & 0.98 \\
		Adapt ordering \& pricing decisions & 1\,550 & 5.71 \\
		Early stopping & 747 & 5.71\\
		\bottomrule
	\end{tabular}
	\caption[Dynamic Programming: Computation Time Improvements]{
	Computation time improvements of the dynamic programming approach with the proposed optimization methods.
	Each row contains the optimizations from the rows above. The last column (Error [\%]) is the percent error between calculated profit $V_0(0)$ and actual expected profit $V^*_0(0)$.}
	\label{tab:speedup}
%calculated expected profits
%18.5891472589,
%18.5045225348,
%17.6215569115,
%17.6215630075,
% actual:
%18.6885701077
\end{table}

Applying all three optimization methods to the dynamic programming approach reduces the computation time in our example from 9.4 seconds to 0.75 seconds, a reduction by 92\%.
This is fast enough to quickly update prices after a new market situation.
These optimizations come at the cost of precision of the dynamic programming approach.
The precision loss for setting the start value to the expected profit from the previous result and for early stopping are neglectable.
In contrast, the adaption of the decision sets introduce an percent error of around 5\% to the resulting expected profit.
Despite the precision error, the computed policies usually are identically to the optimal policy.
We are willing to accept the the loss in precision in order to increase the efficiency of the dynamic programming approach.

\subsection{Merchant Description and Simulation Setup}
\label{section:setup}
%data-driven merchants
Our merchant implementation with the proposed optimization model is called data-driven merchant.
A new training on all training data every minute.
The period length is 4 seconds.
$N_{max} = 40$ and $T = 40$, $d=5$.
The decision spaces are adapted up to 5 times after $T$ iterations each.

%cheapest merchant
Our merchant, called data-driven merchant, competes with two rule-based merchants.
The cheapest merchant always undercuts the cheapest competitor by 0.30.
Only if the cheapest competitor price is higher than the upper price bound of 30, the cheapest merchant sets a price of 30 instead.
If no competitor offer is available, the cheapest merchant sets the price to the upper price bound.
The merchant makes a new order, if the inventory level falls below 6 items.
In that case, the merchant orders as many items as needed to refill the inventory to 20 items.
The period length is 4 seconds.

%two bound merchant
The second rule-based merchant, called two bound merchant, undercuts the cheapest competitor offer by 0.30, similar to the cheapest merchant.
However, the merchant has a upper and lower price bound.
If the cheapest competitor offer price is below the lower price bound of 17, the two bound merchant sets the price to the upper price bound, 30.
Moreover, if no competitor orders are available or all competitor prices are above the upper price bound, the price is also set to the upper price bound.
This merchant makes a new order if the inventory level falls below 4 items.
In that case, the merchant orders as many items as needed to refill the inventory to 15 items.
The period length is 4 seconds.

%consumer
Consumers are configured to visit the marketplace at an average rate of 100 consumers per minute.
The time between arriving consumers is exponential distributed with a mean of 0.6 seconds.
They dismiss offers costing 80 or more.
The remaining $J$ offers $\vec{o} = (o_1, o_2, \ldots, o_J)$ have prices $\vec{p} = (p_1, p_2, \ldots, p_J)$.
The maximal price in $\vec{p}$ is denoted by $p_{max}$, the sum of these prices is denoted by $p_{sum}$.
A consumer buys one item from the remaining offers at random with the probability distribution by \cref{eq:consumer_probs}, j = 1, \ldots, J.

\begin{equation}
P(\text{Buy from } o_j) = \frac{p_{max} + 1 - p_j}{J \cdot (p_{max} + 1) - p_{sum}}
\label{eq:consumer_probs}
\end{equation}

If there are no offers with prices below 80, the consumer leaves the marketplace without buying anything.

Simulations have a duration of 15 minutes.
If not mentioned otherwise, the following simulations are run with the configuration listed here.

\subsection{Duopoly Simulation}
\label{section:duopoly}
We investigate the profitability of the proposed merchant in a duopoly scenario in this section and in an oligopoly scenario in the following section.
Our data-driven merchant competes with each of the rule-based merchants.
In the last duopoly scenario, two data-driven merchants with the same strategy compete with each other.

%%%%%%%%%%%%%%%%%%
%data-driven vs. cheapest
%%%%%%%%%%%%%%%%%%
\subsubsection{Data-Driven Merchant vs. Cheapest Merchant}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/duopoly_cheapest_prices}
	\caption[Price Trajectories: Data-Driven Merchant versus Cheapest Merchant]{Price trajectories in a duopoly of data-driven merchant and cheapest merchant. Parameters as in \cref{section:setup}.}
	\label{fig:duopoly_cheapest}
\end{figure}

We simulated competition in a duopoly between the data-driven and cheapest merchant for 15 minutes.
\cref{fig:duopoly_cheapest} shows how both merchants undercut each other.
With variable order costs of 15, the data-driven merchant does not reduce the price below 20 and instead raises the price to 25/26.
The increased price has lower sales probabilities but a higher profit margin.
The cheapest merchant increases the price sometimes.
When the data-driven merchant is out of stock, there is no competitor offer for the cheapest merchant to undercut.
When this is the case, the cheapest merchant uses a default price.
The final results of this simulation are shown in \cref{tab:duopoly_cheapest}.
The data-driven merchant has overall more costs but makes more profit because of a higher revenue than the cheapest merchant.

\begin{table}[t]
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Merchant} & \textbf{Profit} & \textbf{Revenue} & \textbf{Holding Cost} & \textbf{Order Cost} \\
		\midrule
		Data-Driven & 7\,285.78 & 20\,599.00 & 588.22 & 12\,725.00 \\
		Cheapest & 5\,796.11 & 17\,165.10 & 418.99 & 10\,950.00 \\
		\bottomrule
	\end{tabular}
	\caption[Simulation Results: Data-Driven Merchant versus Cheapest Merchant]{Simulation results of a duopoly with the data-driven and cheapest merchant. Parameters as in \cref{section:setup}.}
	\label{tab:duopoly_cheapest}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%
% data-driven vs. two bound
%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data-Driven Merchant vs. Two Bound Merchant}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/duopoly_bound_prices}
	\caption[Price Trajectories: Data-Driven Merchant versus Two Bound Merchant]{Price trajectories in a duopoly of data-driven merchant and two bound merchant. Parameters as in \cref{section:setup}.}
	\label{fig:duopoly_bound_prices}
\end{figure}

Running a duopoly with the data-driven and two bound merchant does not result in both merchants undercutting each other as we have seen in the previous example between the data-driven and cheapest merchant.
\cref{fig:duopoly_bound_prices} shows that the data-driven merchant offers to a much higher price compared to the competitor.
The two bound merchant sets the price to the maximum that the merchant's configuration allows.

Customers are unlikely to buy from the data-driven merchant if other offers are only at half the price.
However, the data-driven merchant learned that there is a good chance to sell products at a high price because the two bound merchant is prone to stock-outs.

The inventory graph in \cref{fig:duopoly_bound_inventory} shows clearly that the data-driven merchant only sells products if the two bound merchant is out of stock.
Customers start buying the expensive products if no cheaper alternative is available.
The data-driven merchant is able to make more profit than the two bound merchant without offering a cheaper price.
Overall, both merchants made more profit compared to the duopoly with the data-driven and cheapest merchant because they offered products at higher prices.
The results are shown in \cref{tab:duopoly_bound}.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/duopoly_bound_inventory}
	\caption[Inventory Levels: Data-Driven Merchant versus Two Bound Merchant]{Inventory levels over time in a duopoly of data-driven merchant and two bound merchant. The two bound merchant has many stock-out because of reordering only if the inventory level falls below 4 items. Parameters as in \cref{section:setup}.}
	\label{fig:duopoly_bound_inventory}
\end{figure}

\begin{table}[t]
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Merchant} & \textbf{Profit} & \textbf{Revenue} & \textbf{Holding Cost} & \textbf{Order Cost} \\
		\midrule
		Data-Driven & 15\,571.60 & 24\,761.00 & 1\,484.39 & 7\,705.0 \\
		Two Bound & 13\,379.67 & 29\,138.90 & 229.22 & 15\,530.0 \\
		\bottomrule
	\end{tabular}
	\caption[Simulation Results: Data-Driven Merchant versus Two Bound Merchant]{Simulation results of a duopoly with the data-driven and two bound merchant. Parameters as in \cref{section:setup}. Parameters as in \cref{section:setup}.}
	\label{tab:duopoly_bound}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%
% data-driven vs. two bound take 2
%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/duopoly_bound_prices_2}
	\caption[Price Trajectories: Data-Driven Merchant versus Two Bound Merchant with Larger Inventory]{Price trajectories in a duopoly of data-driven merchant and two bound merchant. The two bound merchant restocks the inventory to 25 instead of 15 items and reorders if the inventory falls below 7 instead of 4 items to reduce the number of stock-outs. Other parameters as in \cref{section:setup}.}
	\label{fig:duopoly_bound_prices_2}
\end{figure}

In a second simulation of the competition between the data-driven merchant and the two bound merchant, we increased the number of items the two bound merchant holds.
The two bound merchant restocks to 25 items instead of 15 and makes a new order whenever the inventory level falls below 7 items instead of 4.
This reduces the risks of having stock-outs.

The data-driven strategy from the previous simulation to offer items at a high price alongside the two bound merchant's offers is no longer viable.
The probability to sell items at the previous high prices is small because stock-outs for the two bound merchant are less likely to happen.

The data-driven merchant expects the most profit from undercutting the competitor.
This results in both merchants undercutting each other as shown in \cref{fig:duopoly_bound_prices_2}.
The two bound merchant is programmed to raise the price if it falls below a threshold.
However, the data-driven merchant was the first to increase the price in this simulation.
The results are shown in \cref{tab:duopoly_bound_2}.
Both merchants made less profit compared to the previous simulation because they frequently decrease prices to have the lowest prices.
%why more profit? -> better inventory?

\begin{table}[t]
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Merchant} & \textbf{Profit} & \textbf{Revenue} & \textbf{Holding Cost} & \textbf{Order Cost} \\
		\midrule
		Data-Driven & 5\,858.79 & 18\,984.00 & 595.20 & 12\,530.0 \\
		Two Bound & 5\,230.10 & 16\,952.70 & 527.60 & 11\,195.0 \\
		\bottomrule
	\end{tabular}
	\caption[Simulation Results: Data-Driven Merchant versus Two Bound Merchant with Larger Inventory]{Simulation results of a duopoly with the data-driven and two bound merchant. The two bound merchant holds more items in the inventory to reduce the number of stock-outs. The two bound merchant restocks the inventory to 25 instead of 15 items and reorders if the inventory falls below 7 instead of 4 items to reduce the number of stock-outs. Other parameters as in \cref{section:setup}.}
	\label{tab:duopoly_bound_2}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%
% data-driven vs. data-driven
%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data-Driven Merchant vs. Data-Driven Merchant}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/duopoly_data_prices}
	\caption[Price Trajectories: Data-Driven Merchant versus Data-Driven Merchant]{Price trajectories in a duopoly of two data-driven merchants with the same configuration. Parameters as in \cref{section:setup}.}
	\label{fig:duopoly_data_prices}
\end{figure}

The next simulation is about the competition between two identical copies of our data-driven merchant.
The price chart in \cref{fig:duopoly_data_prices} shows again the typical zig-zag pattern of two merchants undercutting each other and periodically pushing the price up to increase profit margins.
The competition between two data-driven merchants happens at a higher price level (around 32-51) compared to the previous simulation (around 20-26).
This results in an overall higher profit for both competing merchants.
%preisabsprache gibt höchsten profit erwähnen?
The data-driven merchants order new items whenever the inventory level falls below 6 items and restock the inventory to around 28 items.

Results of this simulation are shown in \cref{tab:duopoly_data}.
Merchants do not collect the same sales experiences which may result in different pricing and ordering policies.
Different policies and (bad) luck on customer decisions are the reasons for differences in revenue and costs between both merchants.

\begin{table}[t]
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Merchant} & \textbf{Profit} & \textbf{Revenue} & \textbf{Holding Cost} & \textbf{Order Cost} \\
		\midrule
		Data-Driven   & 17\,361.30 & 30\,936.0 & 804.69 & 12\,770.0 \\
		Data-Driven 2 & 15\,650.58 & 27\,282.0 & 721.41 & 10\,910.0 \\
		\bottomrule
	\end{tabular}
	\caption[Simulation Results: Data-Driven Merchant versus Data-Driven Merchant]{Simulation results of a duopoly with two data-driven merchants with the same configuration. Parameters as in \cref{section:setup}}
	\label{tab:duopoly_data}
\end{table}

\subsection{Oligopoly Simulation}
\label{section:oligopoly}
This section shows how our merchants performs in an oligopoly.
The merchants sell products on the \pricewars platform.
The objective is to maximize the expected discounted profit.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/competition_prices.pdf}
	\caption[Price Trajectories in Oligopoly Scenario]{Price trajectories in an oligopoly scenario on the \pricewars platform. Our data-driven merchant competes with two rule-based merchants. The merchants have a race for the cheapest price. The data-driven merchant sometimes raises the price to increase the price niveau. Parameters as in \cref{section:setup} with a simulation duration of 30 minutes.}
	\label{fig:competition_prices}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/competition_inventory.pdf}
	\caption[Inventory Levels in Oligopoly Scenario]{Inventory levels over time in an oligopoly scenario on the \pricewars platform. Our data-driven merchant competes with two rule-based merchants. Parameters as in \cref{section:setup} with a simulation duration of 30 minutes.}
	\label{fig:competition_inventory}
\end{figure}

We simulated the scenario with competition on the \pricewars platform.
The \ui shows pricing and ordering decisions during the simulation (see \cref{fig:competition_prices,fig:competition_inventory}).
The data-driven merchant learned the advantage of undercutting competitors' offers.
However, this creates a high price competition and offer prices decrease.
With shrinking profit margins, it becomes unprofitable to set the price below competitors' prices.
The data-driven merchant pushes the price up in such a situation.
This action is especially successful if the competitors also increase their offer prices.

\begin{table}[t]
	\centering
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Merchant} & \textbf{Profit} & \textbf{Revenue} & \textbf{Holding Cost} & \textbf{Order Cost} \\
		\midrule
		Data-Driven & 5\,944.13 & 21\,938.00 & 943.87 & 15\,050.00 \\
		Cheapest & 5\,386.90 & 23\,770.80 & 903.89 & 17\,480.00 \\
		Two Bound & 5\,038.63 & 20\,148.30 & 644.67 & 14\,465.00 \\
		\bottomrule
	\end{tabular}
	\caption[Simulation Results of Oligopoly Scenario]{Simulation results of the oligopoly scenario with the data-driven, cheapest, and two bound merchant. The data-driven merchant made the most profit. The cheapest merchant made the most revenue. Parameters as in \cref{section:setup} with a simulation duration of 30 minutes.}
	\label{tab:competition}
\end{table}

\cref{tab:competition} shows the results of a half an hour competition between three merchants.
The data-driven merchant outperformed all competitors.
Our data-driven merchant made around 10\% more profit than the cheapest merchant and 18\% more than the two bound merchant.
Interestingly, our merchant did not make the most revenue, but the cheapest merchant did.
The cheapest merchant sold the most items but with low profit per item.
Our merchant made the most profit by saving a lot of order cost compared the to cheapest merchant.
The data-driven merchant orders on average more items than the competitors.
This results in higher holding costs but saves on fixed order cost.
%todo how did our merchant win?

%command: python3 helper_scripts/benchmark.py -o ../runs -d 30 --merchants "python3 /home/carsten/pricewars-merchant/merchant.py --port 5000 --strategy Cheapest" "python3 /home/carsten/pricewars-merchant/merchant.py --port 5001 --strategy \"Two Bound\"" "python3 /home/carsten/pricewars-merchant/merchant_scenario4.py --port 5002" --holding_cost 3

%todo{show reaction when changing demand or fixed ordering cost}
%

\section{Merchant Implementation}
\label{section:merchant_implementation}
%how is merchant implemented? (language choice)
Merchants on the \pricewars platform can be written in any language as long as they comply with the platform's REST APIs.
We decided to implement our merchant in the Python programming language~\cite{DBLP:conf/usenix/Rossum07} for the following reasons.
Python has great library support for numerical computing.
These libraries allow a concise and efficient implementation without reinventing the wheel.
The \pricewars platform offers a Python implementation of the RESTful API for the merchant to communicate with the platform's services.
Lastly, it is possible to quickly create prototypes in Python.

%architecture
Our merchant consists of four components as it is shown in \cref{fig:merchant_architecture}.
%motivation for this architacture
%main loop
The main loop is the central component.
It regularly checks the marketplace for open offers, updates prices, and orders items from the producer.
After enough time passed, the merchant requests new market and sales data from the kafka reverse proxy and provides it to the demand learning component to analyze demand.

\bgroup
\tikzstyle{block} = [draw, rectangle, minimum height=3em, minimum width=6em]
\tikzstyle{pinstyle} = [pin edge={<-,thin,black}]
\tikzstyle{rpinstyle} = [pin edge={->,thin,black}]

%todo better figure
%server?
%main loop?
%merchant rectangle
%refer to fmc diagram

%reduce tabular row height, bgroup and egroup should limit scope of this command
\renewcommand{\arraystretch}{0.4}

\begin{figure}[t]
\centering
\begin{tikzpicture}[auto, node distance=2cm,>=latex']

\node [block] (demand) {Demand Learning};
\node [block, right of=demand, node distance=5cm] (policy) {Policy Component};
\node [block, below of=demand, pin={[rpinstyle]left:
		\begin{tabular}{@{}cc@{}}
		Marketplace \\
		Producer \\
		Kafka Proxy \\
		\end{tabular}
	}] (main) {Main Loop};
\node [block, right of=main, node distance=3.5cm,
	pin={[pinstyle]right:
		\begin{tabular}{@{}cc@{}}
		Marketplace \\
		\UI \\
		\end{tabular}
	}] (server) {Server};

\draw [->] (server) -- node {forward}(main);
\draw [->] (main) -- node {training data} (demand);
\draw [<-] (main) -- node[sloped, ,pos=0.7] {policies} (policy);
\draw [->] (demand) -- node {predictions} (policy);

\end{tikzpicture}
\caption[Architecture of the Data-Driven Merchant]{Architecture of the Data-Driven Merchant.}
\label{fig:merchant_architecture}
\end{figure}
\egroup

%policy
The merchant makes ordering and pricing decisions based on policies that are computed by the policy component.
The policy component contains the dynamic programming approach.
The merchant provides all arguments that are necessary for the policy creation and sales probabilities are requested from the demand learning component.
%todo ref to equation
The dynamic programming function is the computational most expensive part of the merchant.
An efficient implementation reduces the time needed for a pricing and ordering decision.
We create a vector that has the dimensions inventory levels, ordering decisions, pricing decisions, and demand.
The expected profit is calculated for each possible situation and decision that occur in this vector.
The expected profits are used to find the most profitable decisions and to create the ordering and pricing policy.
We use fast and vectorized array operations from the Numpy library~\cite{dubois1996numerical} to compute the policies.
Python is a high-level programming language and has a lot of computational overhead~\cite{DBLP:journals/cse/BehnelBCDSS11}.
Numpy provides data structures and functions implemented in the C programming language to overcome Python's overhead for numeric computations.

%demand learning
The merchant's demand learning component is responsible for estimating sales probabilities and for bringing market and sales data into a form that can be used for training.
The module uses linear regression to learn and predict the demand.
We use the scikit-learn library~\cite{DBLP:journals/jmlr/PedregosaVGMTGBPWDVPCBPD11} for a reliable and fast linear regression implementation.
As an additional benefit, it is easy to change between regression algorithms using scikit-learn.
The demand learning is implemented in a way that make it easy to add new or change existing explanatory variables.
Only only single function (named \texttt{extract\_features}) must be changed to add new explanatory variables.

%server
The merchant server receives sales events from the marketplace and triggers the appropriate action.
In our case, the merchants prints a message to notify the user whenever an item was sold.
Moreover, the server receives configuration updates from the \ui and applies them.  

The merchant's code is open source and can be found on Github: \url{https://github.com/CarstenWalther/pricewars-merchant}.

%dummy offer
%show merchant main loop as code?
%write about pandas and data transformation?